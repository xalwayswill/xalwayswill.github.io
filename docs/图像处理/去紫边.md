[code](https://github.com/mjambon/purple-fringe)
[转载](https://blog.csdn.net/Aoman_Hao/article/details/105753372)
[转载](https://blog.csdn.net/Aoman_Hao/article/details/113797420)
[ISP相关个人主页]( https://www.qinxing.xyz/posts/e72969e7/)

## 个人理解
###成因
感觉主要两方面，一是镜头色差（主要），二是demosaic造成的图像边缘的false color
镜头尽量满足可见光部分多数区域对焦需求，而对于短波长（紫光，紫外线）产生相反影响，最终导致图像出现紫边模糊。
**高亮，高对比度（边缘），远离中心（横向色差越明显）**

#### 1. 轴向色差

由于传感器对绿色敏感，通常以绿色平面作为基准。聚焦后，绿色光束经过透镜，形成了一个绿色的点，而红色和蓝色在sensor上形成了一个弥散圆。右侧是轴向色差的效果图，理想中应该是黑色的图上一个个白点，实际效果是白点周围包裹着一层紫边
![](去紫边.assets\23495115-aa1350eb19300854.png)

特点
色差颜色随着焦点的移动而变化的时候（手动调整聚焦位置），我们认为出现了纵向色差，举个例子，焦点在前面会偏紫，焦点在后面会偏绿，就是纵向色差
缩小光圈可以抑制纵向色差（因为缩小光圈可以缩小弥散圆）
如果在画面中央出现，也可以认为是纵向色差，因为横向一般边缘更加严重，纵向色差的分布均匀的分布在整张图像内
####2. 横向色差

大部分场景都是横向色差。不同波长的光经过透镜折射后，落在sensor横向上的不同位置上。从右侧的图可以看出，中心的色差很小，边缘的色差很大，由内而外，色差的颜色依次以红黄蓝的顺序变化。
![](去紫边.assets\23495115-082867c6a69e73b8.png)

特点
拍摄一个物体的时候，在物体的一侧出现紫边，在另外一侧出现另外一种颜色，如绿边
从图像中心到边缘，横向色差会变得越来越严重
调节光圈无法减弱紫边
所以需要radial weight


###现象
高反差， 大背光图像时候容易出现，示例图片如下面的dog
##处理方法
产生蓝色蒙版减去部分蓝色分量？



图像紫边存在数码相机、监控摄像头等数字成像图像，使用设备在逆光、大光圈条件下拍摄图像的高反差区域容易出现紫边，解决图像自编问题有助设备得到完美图像。

紫边成因分析和确定有助与紫边消除的图像处理算法研究和摄像设备工程改进，能够改善自编的硬件成本更高，非常需要研究去除紫边的图像处理算法。

## 紫边
通过取色器中对“紫边”的色彩分析，可以发现，大部分紫边的主要构成就是洋红，这些紫边是由于高反差大背光静物边缘，产生光学衍射，加上DC/DV的CCD在色彩插值导致。

因为人对红、绿、蓝三种颜色的中绿分量比较敏感，大多sensor的bayer排列大多采样绿分量比较多，例如RGGB排列。
绿色采样结果比较多,相比红色和蓝色通道来说不容易发生混叠，而红蓝分量组合后表现为洋红色，与取色器的表现接近。

硬件改善紫边（镜头、sensor）
尽量选择低色差的镜头，验证色差曲线。sensor选择像元面积较大，保证光入射角度较大，亦可以规避shading问题。

算法改善
在RGB域检测紫边
## 高亮区域检测
首先对R、G、B分别设置固定的亮度阈值，把图像分为很多块，精确一点可以选择5*5大小的邻域，粗糙一点可以选13*13，判断邻域内每一个像素点的R、G、B值是否超过R、G、B初设亮度阈值（可能不同），邻域内超过R、G、B初设亮度阈值的像素记录数目分别为RNum、GNum、BNum，，当RNum、GNum、BNum同时满足＞设定的高亮区域像素数阈值（R、G、B三通道可能不同）时，判定该区域为高亮区域。

## 边缘区域检测
既可以使用常用的边缘检测算子Roberts 梯度算子、拉普拉斯梯度算子等，也可以分析像素区域方差趋势来判断是否属于边缘。统计区域内像素方差，判断方差值与初设方差阈值的大小，只有大于该阈值的区域才被认为是边缘。

满足以上高亮和边缘区域多个条件的像素可以认为是紫边。

矫正紫边
紫边区域紫色饱和度淡化，具体措施不晓得，再看看文献好了


# Unpurple

Unpurple is a tool for removing purple fringes (axial chromatic aberration) from digital photos using a heuristic of my own.

This is the original OCaml implementation which produces a standalone executable with a simple command-line interface. It is fast enough (~ one second per megapixel) but doesn't preserve Exif data and the JPEG compression factor is fixed at 75%.

Unpurple was [ported](https://github.com/dtschump/gmic-community/blob/master/include/stanislav_paskalev.gmic) to [G'MIC](https://gmic.eu/) by [Stanislav Paskalev](https://github.com/solarsea), allowing its use from [GIMP](https://www.gimp.org/) and other image-manipulation software. 

## [](https://github.com/mjambon/purple-fringe#example)Example

Before:

[![Before](https://upload-images.jianshu.io/upload_images/23495115-c0d04d2db432e0bb?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)](https://github.com/mjambon/purple-fringe/blob/master) 

After:

[![After](https://upload-images.jianshu.io/upload_images/23495115-7fb33341d7f245e2?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)](https://github.com/mjambon/purple-fringe/blob/master) 

Difference:

[![Difference](https://upload-images.jianshu.io/upload_images/23495115-5d527f0d61e751bd?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)](https://github.com/mjambon/purple-fringe/blob/master) 

[More examples](https://mjambon.github.io/mjambon2016/purple-fringe/examples.html)

## [](https://github.com/mjambon/purple-fringe#algorithm-outline)Algorithm outline

1.  Produce a blurred mask from the blue component in the original image.
2.  Subtract from the original image some amount of blue and red based on the intensities found in the blurred mask, using the following constraints:
    *   Blue level may not drop below green level.
    *   Red level may not drop below green level.
    *   Red:blue ratio may not drop below some constant.

Please refer to the implementation for details and default parameters.

## [](https://github.com/mjambon/purple-fringe#intuition-and-future-prospects)Intuition and future prospects

The original motivation for this work was to remove purple fringing from my own photos that I took with a relatively cheap lens. Coming up with an algorithm required:

1.  Notions about optics, and in particular understanding why chromatic aberration happens.
2.  Notions about image manipulation and RGB color encoding.
3.  Notions about the visible spectrum (rainbow) and how wavelengths map to certain perceived colors.
4.  Notions about the perception of colors in humans and why computers encode colors as 3 components (excluding brightness or transparency) and not another number.

It is useful, or perhaps critical, to understand why mixing blue and red dots produces a perception of purple, even though none of the light emitted from blue and red dots needs to have the wavelength of the purple band of the rainbow. School and Wikipedia are your friends.

Here's my mental model of purple fringing, which may be inacurrate but turned out to be good enough. It may not work as well or at all for other types of chromatic aberration:

A camera "lens" is made of several simple lenses, which help not only with zooming in, but also correcting for certain problems. My understanding is that they allow multiple regions of the visible spectrum to remain in focus, but this has the opposite effect on the short wavelengths (purple and ultraviolet) which end up very blurred out. It is also possible that UV light is captured as purple by the sensor of a digital camera. As a result, black objects on a white background will exhibit a purple fringe all around. Note that this is different then some other types of chromatic aberration, where some objects have a red margin on one side and a blue margin on the other side.

Now for the method. The problem of removing the purple fringe is tackled by observing that the bright parts of the image still contain most of the purple that they should contain. We don't need to take the purple from the purple fringes and put it back into the bright areas. They're still plenty bright and their colors look natural. We assume that they still contain most of the indigo-purple color corresponding to the short wavelengths, in the correct location. So instead of trying to locate a purple fringe in the hope of removing it, we create a purple fringe from the image which already has a purple fringe. This involves selecting the blue-purple component of the image, which is a combination of blue and red within some acceptable ratio and blurring it. The result is a mask that if added to the original image would produce a purple fringe roughly like the one we want to remove. What remains to do is somehow subtract this approximate artificial purple fringe mask from the original. The first problem is that our artificial fringe is most likely wider and more intense that the actual fringe we want to remove, and we don't want to remove too much so as to not introduce new colors. The second problem is that we don't want to remove the blue-purple component from the bright areas of the image. These problems are solved by:

1.  Subtracting the purple mask only where it's brighter than the original purple component.
2.  Subtracting purple only from regions that are somewhat purple, and at most until they look grey. For example, from a dark purplish pixel like (red = 0.3, green = 0.1, blue = 0.3), we may consider a purple fringe mask of (0.25, 0, 0.25). If we subtracted this mask directly, we would get (0.05, 0.1, 0.05) and now the pixel would be greenish! We avoid this by ensuring that at worst we turn a pixel grey. In this case, our resulting pixel would be (0.1, 0.1, 0.1), which is a dark grey rather than an undesirable dark green.

This is what the current transformations try to do, and it works often well, which is sometimes surprising. Some areas where a purple fringe was removed look greyer than they probably should, but the grey color has the advantage of being discreet.

Some people have asked about removing green fringing. The current algorithm won't remove it. However, it's possible that a similar algorithm would work. I estimate it would take at least a couple of days to obtain a proof of concept, if it is feasible. I hope the explanations above may help whoever is interested in adding support for green-fringe removal.
